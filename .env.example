# Optional LLM provider settings
LLM_PROVIDER=mock  # mock | openai
OPENAI_API_KEY=your_key_here
OPENAI_MODEL=gpt-4o-mini
RETRIEVAL_BACKEND=tfidf

# Retrieval
INCIDENTS_PATH=app/data/incidents_seed.json
TOP_K_DEFAULT=2

DEBUG_LOGS=true
DEBUG_LLM=true

COST_PER_1K_INPUT_TOKENS_USD=0.0005
COST_PER_1K_OUTPUT_TOKENS_USD=0.0015